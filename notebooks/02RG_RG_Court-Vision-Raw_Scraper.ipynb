{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02RG. RG Court Vision Raw Data Scraper\n",
    "\n",
    "Notebook will contain codes and functions for scraping the court vision raw data from the Roland Garros website.\n",
    "Output is archived in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import itertools\n",
    "import sys\n",
    "sys._enablelegacywindowsfsencoding() #Deal with pandas problem with reading file with accents in file path i.e Alexis Sánchez, Victor Lindelöf \n",
    "\n",
    "\n",
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'} \n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import base64\n",
    "import cryptography.hazmat.backends\n",
    "import cryptography.hazmat.primitives.ciphers\n",
    "import cryptography.hazmat.primitives.ciphers.algorithms\n",
    "import cryptography.hazmat.primitives.ciphers.modes\n",
    "import cryptography.hazmat.primitives.padding\n",
    "\n",
    "import sys\n",
    "from time import sleep\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decrypting Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatDate(t):\n",
    "    #e = datetime.datetime.now().utcoffset().total_seconds() / 60       # ChatGPT suggestion but not needed\n",
    "    #t = t + datetime.timedelta(minutes=e)                              # ChatGPT suggestion but not needed\n",
    "    \n",
    "    t_tstamp = datetime.datetime.utcfromtimestamp(t/1000)\n",
    "    n = t_tstamp.day\n",
    "    r = int(str(n if n >= 10 else \"0\" + str(n))[::-1])\n",
    "    i = t_tstamp.year\n",
    "    a = int(str(i)[::-1])\n",
    "    o = np.base_repr(int(str(t), base=16), 36).lower() + np.base_repr((i + a) * (n + r), 24).lower()\n",
    "    s = len(o)\n",
    "    if s < 14:\n",
    "        o += \"0\" * (14 - s)\n",
    "    elif s > 14:\n",
    "        o = o[:14]\n",
    "    return \"#\" + o + \"$\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(data):\n",
    "    e = formatDate(data['lastModified'])\n",
    "    n = e.encode()\n",
    "    r = e.upper().encode()\n",
    "    cipher = cryptography.hazmat.primitives.ciphers.Cipher(\n",
    "        cryptography.hazmat.primitives.ciphers.algorithms.AES(n),\n",
    "        cryptography.hazmat.primitives.ciphers.modes.CBC(r),\n",
    "        backend=cryptography.hazmat.backends.default_backend()\n",
    "    )\n",
    "    decryptor = cipher.decryptor()\n",
    "    i = decryptor.update(base64.b64decode(data['response'])) + decryptor.finalize()\n",
    "    unpadder = cryptography.hazmat.primitives.padding.PKCS7(128).unpadder()\n",
    "    #return json.loads(unpadder.update(i) + unpadder.finalize().decode('utf-8'))\n",
    "    return json.loads(i.decode(\"utf-8\").replace(i.decode(\"utf-8\")[-1],\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Match Data and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv(\"../data/RG_results-all_processed_2021.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_scp = matches[matches.id.str.contains(\"SM\")]\n",
    "matches_scp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventId = 520\n",
    "year = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through matches and scrape one by one \n",
    "for i in np.arange(0,1):\n",
    "    try:\n",
    "        match_id = matches_scp.id.iloc[i]\n",
    "        player1 = matches_scp.player1_name.iloc[i]\n",
    "        player2 = matches_scp.player2_name.iloc[i]\n",
    "\n",
    "        link = f\"https://itp-rg-sls.infosys-platforms.com/prod/api/court-vision/year/{year}/eventId/{eventId}/matchId/{match_id}/pointId/0_0_0\"\n",
    "        # Get request and content from the given link and parse into HTML\n",
    "        pageTree = requests.get(link, headers=headers)\n",
    "        pageSoup = BeautifulSoup(pageTree.content, 'html.parser') \n",
    "\n",
    "        results_json = json.loads(str(pageSoup))\n",
    "\n",
    "        # Decode Data\n",
    "        raw_data = decode(results_json)\n",
    "\n",
    "        # Match the formatting of player1/2 to that in the court-vision raw data's player data \n",
    "        # If player names match their respective indexes in the court-vision raw data, \n",
    "        # then we keep the player name order, otherwise we swap \n",
    "        # \"Truncated Name\" for player 1 (e.g. R. NADAL)\n",
    "        player1_tname = player1.split(\" \")[0][0]+\".\" + player1.split(\" \")[1].upper()\n",
    "        player1_cv = raw_data['courtVisionData'][0]['a79']['a83'][0]['a85']\n",
    "\n",
    "        if player1_tname == player1_cv:\n",
    "            player1_cvfile = player1\n",
    "            player2_cvfile = player2\n",
    "        else:\n",
    "            player1_cvfile = player2\n",
    "            player2_cvfile = player1\n",
    "\n",
    "        # Formatting\n",
    "        player1_cvfile = player1_cvfile.replace(\" \",\"-\")\n",
    "        player2_cvfile = player2_cvfile.replace(\" \",\"-\")\n",
    "\n",
    "        # Format the \"Round Name\" to appear on file path\n",
    "        round_n = matches_scp[\"round\"].iloc[i]\n",
    "        if round_n == \"First Round\":\n",
    "            round_short = \"R128\"\n",
    "        elif round_n == \"Second Round\":\n",
    "            round_short = \"R64\"\n",
    "        elif round_n == \"Third Round\":\n",
    "            round_short = \"R32\"\n",
    "        elif round_n == \"Fourth Round\":\n",
    "            round_short = \"R16\"\n",
    "        elif round_n == \"Quarterfinals\" or round_n == \"Quarter-Finals\":\n",
    "            round_short = \"QF\"\n",
    "        elif round_n == \"Semifinals\" or round_n == \"Semi-Finals\":\n",
    "            round_short = \"SF\"\n",
    "        elif round_n == \"Final\" or round_n == \"Finals\":\n",
    "            round_short = \"F\"\n",
    "\n",
    "        # Output the decoded courtvision data into a json file\n",
    "        with open(f\"../data/court-vision/{eventId}_{round_short}_{player1_cvfile}-vs-{player2_cvfile}_{year}_{match_id}_court-vision.json\", 'w') as fp:\n",
    "            json.dump(raw_data, fp)\n",
    "\n",
    "        sleeptime = np.random.uniform(3, 20)\n",
    "        sleep(sleeptime)\n",
    "\n",
    "    except:\n",
    "        print(f\"{i} Failed or no Data!\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_scp = matches[matches.id.str.contains(\"SD\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 Failed or no Data!\n",
      "7 Failed or no Data!\n",
      "8 Failed or no Data!\n",
      "9 Failed or no Data!\n",
      "10 Failed or no Data!\n",
      "11 Failed or no Data!\n",
      "12 Failed or no Data!\n",
      "13 Failed or no Data!\n",
      "14 Failed or no Data!\n",
      "15 Failed or no Data!\n",
      "16 Failed or no Data!\n",
      "17 Failed or no Data!\n",
      "18 Failed or no Data!\n",
      "19 Failed or no Data!\n",
      "26 Failed or no Data!\n",
      "27 Failed or no Data!\n",
      "28 Failed or no Data!\n",
      "29 Failed or no Data!\n",
      "30 Failed or no Data!\n",
      "31 Failed or no Data!\n",
      "32 Failed or no Data!\n",
      "33 Failed or no Data!\n",
      "34 Failed or no Data!\n",
      "35 Failed or no Data!\n",
      "36 Failed or no Data!\n",
      "37 Failed or no Data!\n",
      "38 Failed or no Data!\n",
      "39 Failed or no Data!\n",
      "40 Failed or no Data!\n",
      "41 Failed or no Data!\n",
      "42 Failed or no Data!\n",
      "43 Failed or no Data!\n",
      "50 Failed or no Data!\n",
      "51 Failed or no Data!\n",
      "52 Failed or no Data!\n",
      "53 Failed or no Data!\n",
      "54 Failed or no Data!\n",
      "55 Failed or no Data!\n",
      "56 Failed or no Data!\n",
      "57 Failed or no Data!\n",
      "58 Failed or no Data!\n",
      "59 Failed or no Data!\n",
      "60 Failed or no Data!\n",
      "61 Failed or no Data!\n",
      "62 Failed or no Data!\n",
      "63 Failed or no Data!\n",
      "70 Failed or no Data!\n",
      "71 Failed or no Data!\n",
      "72 Failed or no Data!\n",
      "73 Failed or no Data!\n",
      "74 Failed or no Data!\n",
      "75 Failed or no Data!\n",
      "76 Failed or no Data!\n",
      "77 Failed or no Data!\n",
      "84 Failed or no Data!\n",
      "85 Failed or no Data!\n",
      "86 Failed or no Data!\n",
      "87 Failed or no Data!\n",
      "88 Failed or no Data!\n",
      "89 Failed or no Data!\n",
      "90 Failed or no Data!\n",
      "91 Failed or no Data!\n",
      "92 Failed or no Data!\n",
      "93 Failed or no Data!\n",
      "100 Failed or no Data!\n",
      "101 Failed or no Data!\n",
      "108 Failed or no Data!\n",
      "109 Failed or no Data!\n"
     ]
    }
   ],
   "source": [
    "# Loop through matches and scrape one by one \n",
    "for i in np.arange(0,len(matches_scp)):\n",
    "    try:\n",
    "        match_id = matches_scp.id.iloc[i]\n",
    "        player1 = matches_scp.player1_name.iloc[i]\n",
    "        player2 = matches_scp.player2_name.iloc[i]\n",
    "\n",
    "        link = f\"https://itp-rg-sls.infosys-platforms.com/prod/api/court-vision/year/{year}/eventId/{eventId}/matchId/{match_id}/pointId/0_0_0\"\n",
    "        # Get request and content from the given link and parse into HTML\n",
    "        pageTree = requests.get(link, headers=headers)\n",
    "        pageSoup = BeautifulSoup(pageTree.content, 'html.parser') \n",
    "\n",
    "        results_json = json.loads(str(pageSoup))\n",
    "\n",
    "        # Decode Data\n",
    "        raw_data = decode(results_json)\n",
    "\n",
    "        # Match the formatting of player1/2 to that in the court-vision raw data's player data \n",
    "        # If player names match their respective indexes in the court-vision raw data, \n",
    "        # then we keep the player name order, otherwise we swap \n",
    "        # \"Truncated Name\" for player 1 (e.g. R. NADAL)\n",
    "        player1_tname = player1.split(\" \")[0][0]+\".\" + player1.split(\" \")[1].upper()\n",
    "        player1_cv = raw_data['courtVisionData'][0]['a79']['a83'][0]['a85']\n",
    "\n",
    "        if player1_tname == player1_cv:\n",
    "            player1_cvfile = player1\n",
    "            player2_cvfile = player2\n",
    "        else:\n",
    "            player1_cvfile = player2\n",
    "            player2_cvfile = player1\n",
    "\n",
    "        # Formatting\n",
    "        player1_cvfile = player1_cvfile.replace(\" \",\"-\")\n",
    "        player2_cvfile = player2_cvfile.replace(\" \",\"-\")\n",
    "\n",
    "        # Format the \"Round Name\" to appear on file path\n",
    "        round_n = matches_scp[\"round\"].iloc[i]\n",
    "        if round_n == \"First Round\":\n",
    "            round_short = \"R128\"\n",
    "        elif round_n == \"Second Round\":\n",
    "            round_short = \"R64\"\n",
    "        elif round_n == \"Third Round\":\n",
    "            round_short = \"R32\"\n",
    "        elif round_n == \"Fourth Round\":\n",
    "            round_short = \"R16\"\n",
    "        elif round_n == \"Quarterfinals\" or round_n == \"Quarter-Finals\":\n",
    "            round_short = \"QF\"\n",
    "        elif round_n == \"Semifinals\" or round_n == \"Semi-Finals\":\n",
    "            round_short = \"SF\"\n",
    "        elif round_n == \"Final\" or round_n == \"Finals\":\n",
    "            round_short = \"F\"\n",
    "\n",
    "        # Output the decoded courtvision data into a json file\n",
    "        with open(f\"../data/court-vision/{eventId}_{round_short}_{player1_cvfile}-vs-{player2_cvfile}_{year}_{match_id}_court-vision.json\", 'w') as fp:\n",
    "            json.dump(raw_data, fp)\n",
    "\n",
    "        sleeptime = np.random.uniform(3, 20)\n",
    "        sleep(sleeptime)\n",
    "\n",
    "    except:\n",
    "        print(f\"{i} Failed or no Data!\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "footyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0c9a93429a88daf4bf2a05c7cf40bbe3f1288a690c5bbe3660b2858e5ac0985"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
