{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02r. ATP Court Vision Raw Data Scraper\n",
    "\n",
    "Notebook will contain codes and functions for scraping the court vision raw data from the ATP website.\n",
    "Output is archived in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import itertools\n",
    "import sys\n",
    "sys._enablelegacywindowsfsencoding() #Deal with pandas problem with reading file with accents in file path i.e Alexis Sánchez, Victor Lindelöf \n",
    "\n",
    "\n",
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'} \n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import base64\n",
    "import cryptography.hazmat.backends\n",
    "import cryptography.hazmat.primitives.ciphers\n",
    "import cryptography.hazmat.primitives.ciphers.algorithms\n",
    "import cryptography.hazmat.primitives.ciphers.modes\n",
    "import cryptography.hazmat.primitives.padding\n",
    "\n",
    "import sys\n",
    "from time import sleep\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decrypting Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatDate(t):\n",
    "    #e = datetime.datetime.now().utcoffset().total_seconds() / 60       # ChatGPT suggestion but not needed\n",
    "    #t = t + datetime.timedelta(minutes=e)                              # ChatGPT suggestion but not needed\n",
    "    \n",
    "    t_tstamp = datetime.datetime.utcfromtimestamp(t/1000)\n",
    "    n = t_tstamp.day\n",
    "    r = int(str(n if n >= 10 else \"0\" + str(n))[::-1])\n",
    "    i = t_tstamp.year\n",
    "    a = int(str(i)[::-1])\n",
    "    o = np.base_repr(int(str(t), base=16), 36).lower() + np.base_repr((i + a) * (n + r), 24).lower()\n",
    "    s = len(o)\n",
    "    if s < 14:\n",
    "        o += \"0\" * (14 - s)\n",
    "    elif s > 14:\n",
    "        o = o[:14]\n",
    "    return \"#\" + o + \"$\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(data):\n",
    "    e = formatDate(data['lastModified'])\n",
    "    n = e.encode()\n",
    "    r = e.upper().encode()\n",
    "    cipher = cryptography.hazmat.primitives.ciphers.Cipher(\n",
    "        cryptography.hazmat.primitives.ciphers.algorithms.AES(n),\n",
    "        cryptography.hazmat.primitives.ciphers.modes.CBC(r),\n",
    "        backend=cryptography.hazmat.backends.default_backend()\n",
    "    )\n",
    "    decryptor = cipher.decryptor()\n",
    "    i = decryptor.update(base64.b64decode(data['response'])) + decryptor.finalize()\n",
    "    unpadder = cryptography.hazmat.primitives.padding.PKCS7(128).unpadder()\n",
    "    #return json.loads(unpadder.update(i) + unpadder.finalize().decode('utf-8'))\n",
    "    return json.loads(i.decode(\"utf-8\").replace(i.decode(\"utf-8\")[-1],\"\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Match Data and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(\"../data/atp-tournament-matches/202*/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = file_list[1]\n",
    "matches = pd.read_csv(file)\n",
    "\n",
    "df_tourns = pd.read_csv(\"../data/tournaments_ATP_2022.csv\")\n",
    "list_tourns = df_tourns[df_tourns.Category==\"ATP 250\"].Tournament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv(file)\n",
    "\n",
    "# Subset matches to scrape (exclude qualifying)\n",
    "matches_scp = matches[~matches[\"round\"].str.contains(\"Qualifying\")]\n",
    "\n",
    "matches_scp = matches[(matches.court_vision==1) & (matches.tournament.isin(list_tourns)) & ~(matches[\"round\"].str.contains(\"Qualifying\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches_scp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411 Failed or no Data!\n",
      "417 Failed or no Data!\n",
      "419 Failed or no Data!\n",
      "423 Failed or no Data!\n",
      "466 Failed or no Data!\n",
      "469 Failed or no Data!\n",
      "476 Failed or no Data!\n",
      "477 Failed or no Data!\n",
      "478 Failed or no Data!\n",
      "479 Failed or no Data!\n",
      "484 Failed or no Data!\n",
      "493 Failed or no Data!\n",
      "494 Failed or no Data!\n",
      "498 Failed or no Data!\n",
      "505 Failed or no Data!\n"
     ]
    }
   ],
   "source": [
    "# Loop through matches and scrape one by one \n",
    "for i in np.arange(400,518):\n",
    "\n",
    "    try:\n",
    "        _,_,_,_,_,_,_,year,tourn_id,match_id = matches_scp.url.iloc[i].split('/')\n",
    "    \n",
    "        match_id = match_id.upper()\n",
    "        #print(match_id)\n",
    "\n",
    "        player1 = matches_scp.player1_name.iloc[i]\n",
    "        player2 = matches_scp.player2_name.iloc[i]\n",
    "\n",
    "        link = f'https://itp-atp-sls.infosys-platforms.com/static/prod/court-vision/{year}/{tourn_id}/{match_id}/data.json'\n",
    "        # Get request and content from the given link and parse into HTML\n",
    "        pageTree = requests.get(link, headers=headers)\n",
    "        pageSoup = BeautifulSoup(pageTree.content, 'html.parser') \n",
    "\n",
    "        results_json = json.loads(str(pageSoup))\n",
    "\n",
    "        # Decode Data\n",
    "        raw_data = decode(results_json)\n",
    "\n",
    "        # Match the formatting of player1/2 to that in the court-vision raw data's player data \n",
    "        # If player names match their respective indexes in the court-vision raw data, \n",
    "        # then we keep the player name order, otherwise we swap \n",
    "        # \"Truncated Name\" for player 1 (e.g. R. NADAL)\n",
    "        player1_tname = player1.split(\" \")[0][0]+\".\" + \" \" + player1.split(\" \")[1].upper()\n",
    "        player1_cv = raw_data['courtVisionData'][0]['a79']['a83'][0]['a85']\n",
    "\n",
    "        if player1_tname == player1_cv:\n",
    "            player1_cvfile = player1\n",
    "            player2_cvfile = player2\n",
    "        else:\n",
    "            player1_cvfile = player2\n",
    "            player2_cvfile = player1\n",
    "\n",
    "        # Formatting\n",
    "        player1_cvfile = player1_cvfile.replace(\" \",\"-\")\n",
    "        player2_cvfile = player2_cvfile.replace(\" \",\"-\")\n",
    "\n",
    "        # Format the \"Round Name\" to appear on file path\n",
    "        round_n = matches_scp[\"round\"].iloc[i]\n",
    "        if \"Round Of\" in round_n:\n",
    "            round_short = round_n.split(\" \")[0][0] + round_n.split(\" \")[-1]\n",
    "        elif \"Round\" in round_n:\n",
    "            round_short = \"\".join([s[0] for s in round_n.split(\" \")])\n",
    "        elif round_n == \"Quarterfinals\" or round_n == \"Quarter-Finals\":\n",
    "            round_short = \"QF\"\n",
    "        elif round_n == \"Semifinals\" or round_n == \"Semi-Finals\":\n",
    "            round_short = \"SF\"\n",
    "        elif round_n == \"Final\" or round_n == \"Finals\":\n",
    "            round_short = \"F\"\n",
    "\n",
    "        # Output the decoded courtvision data into a json file\n",
    "        with open(f\"../data/court-vision/{tourn_id}_{round_short}_{player1_cvfile}-vs-{player2_cvfile}_{year}_{match_id}_court-vision.json\", 'w') as fp:\n",
    "            json.dump(raw_data, fp)\n",
    "\n",
    "        sleeptime = np.random.uniform(3, 20)\n",
    "        sleep(sleeptime)\n",
    "\n",
    "    except:\n",
    "        print(f\"{i} Failed or no Data!\")\n",
    "        pass\n",
    "\n",
    "sleeptime = np.random.uniform(25, 60)\n",
    "sleep(sleeptime)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out Court Vision pages (and data) only started existing on the ATP website from 2022 onwards. \"Second Screen\" pages have different underlying data that dont have information such as current match state, ball speed, ball trajectory during rallies etc. Instead there are serve and return locations, but seemingly not in sequential (by-points) order."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "footyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0c9a93429a88daf4bf2a05c7cf40bbe3f1288a690c5bbe3660b2858e5ac0985"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
